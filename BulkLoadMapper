package com.lxmt.multiinsert;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.hbase.Cell;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.client.Put;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.ByteArrayOutputStream;
import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.Enumeration;
import java.util.Random;
import java.util.zip.ZipEntry;
import java.util.zip.ZipFile;

public class BulkLoadMapper extends Mapper<LongWritable, Text, ImmutableBytesWritable, Put> {

  byte[] buf = new byte[1024];

  @Override
  protected void setup(Context context) throws IOException, InterruptedException {
    Configuration conf = context.getConfiguration();
  }

  @Override
  protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
    String[] valuePair = value.toString().split(":");
    Put p =new Put(valuePair[1].getBytes());
    p.addColumn(Bytes.toBytes("cf1"),Bytes.toBytes("columnName"),Bytes.toBytes("colVal"));
    if(valuePair[0].startsWith("A")){
    	context.write(new ImmutableBytesWritable(Bytes.toBytes("TableA")), p);
    }
    else
    {
    	context.write(new ImmutableBytesWritable(Bytes.toBytes("TableB")), p);
    }
    } 
  
 }
